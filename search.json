[
  {
    "objectID": "quarto-workflows/jupyter.html",
    "href": "quarto-workflows/jupyter.html",
    "title": "From Jupyter",
    "section": "",
    "text": "You can interact with Quarto through JupyterLab or JupyterHub. Your Jupyter setup will involve .ipynb notebooks and the command line. Quarto’s JupyterLab tutorials has great instructions on getting started with JupyterLab, including computations and authoring.\nHere we will demonstrate how to work with this Quarto tutorial site in JupyterHub and add a Jupyter Notebook (.ipynb file). This example uses the NASA-Openscapes JupyterHub that already has all python environments as well as Quarto installed."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#setup",
    "href": "quarto-workflows/jupyter.html#setup",
    "title": "From Jupyter",
    "section": "Setup",
    "text": "Setup\n\nJupyterHub\nOur JupyterHub is already setup with python environments as well as Quarto (through nasa-openscapes/corn), so there is no further installation required.\n\n\nClone your repo\nYou’ll start by cloning your repository into JupyterHub. Do this by opening a terminal (File > New > Terminal). In the Terminal, git clone your repository and cd into it:\ngit clone https://github.com/openscapes/quarto-website-tutorial\ncd quarto-website-tutorial\n\n\nInstall Quarto\nNot needed - Quarto is already installed on the NASA-Openscapes JupyterHub! But to install elsewhere you would do so from https://quarto.org/docs/get-started/.\nQuarto is a Command Line Interface (CLI), like git. Once download is complete, follow the installation prompts on your computer like you do for other software. You won’t see an application to click on when it is installed.\nNote for Mac users: If you do not have administrative privileges, please select “Install for me only” during the Destination Selection installation step (you will first click on “Change Install Location” at the Installation Type step).\nYou can check to confirm that Quarto is installed properly from the command line:\nquarto check install\n\n\n\n\n\n\nAdditional checks\n\n\n\n\n\nYou can also run:\n\nquarto check knitr to locate R, verify we have the rmarkdown package, and do a basic render\nquarto check jupyter to locate Python, verify we have Jupyter, and do a basic render\nquarto check to run all of these checks together\n\n\n\n\n\n\n\n\n\n\nHistorical aside: Install Quarto in a docker container\n\n\n\n\n\nIn Summer 2021 some NASA Mentors trying to install quarto locally was not an option, but they were able to install it inside a container using the following Dockerfile:\n#| fold: true\n#| summary: \"Show the Dockerfile\"\n\n##############################\n# This Dockerfile installs quarto and then runs quarto serve against the\n# internal /home/quarto/to_serve.\n#\n# BUILD\n# -----\n# To build this container, run\n#\n#     docker build -t quarto_serve .\n#\n# Add the --no-cache option to force docker to build fresh and get the most\n# recent version of quarto.\n#\n#\n# RUN\n# ---\n# 1. Find the directory you want quarto to serve. Let's call this /PATH/TO/earthdata-cloud-cookbook.\n# 2. Run docker:\n#\n#     docker run --rm -it -p 4848:4848 -v /PATH/TO/earthdata-cloud-cookbook:/home/quarto/to_serve quarto_serve\n#\n# 3. Open your browser and go to http://127.0.0.1:4848/\n#\n##############################\n\nFROM ubuntu:hirsute\n\n######\n# Install some command line tools we'll need\n######\nRUN apt-get update\nRUN apt-get -y install wget\nRUN apt-get -y install gdebi-core\nRUN apt-get -y install git\n\n\n######\n# Install quarto (https://quarto.org/)\n######\n\n# This is a quick and dirty way of getting the newest version number from\n# https://github.com/quarto-dev/quarto-cli/releases/latest. What's happening is\n# we're pulling the version number out of the redirect URL. This will end up\n# with QVER set to something like 0.2.11.\nRUN QVER=`wget --max-redirect 0 https://github.com/quarto-dev/quarto-cli/releases/latest 2>&1 | grep \"Location\" | sed 's/L.*tag\\/v//' | sed 's/ .*//'` \\\n    && wget -O quarto.deb \"https://github.com/quarto-dev/quarto-cli/releases/download/v$QVER/quarto-$QVER-amd64.deb\"\nRUN gdebi -n quarto.deb\n\n# Run this to make sure quarto installed correctly\nRUN quarto check install\n\n\n######\n# Create a non-root user called quarto\n######\nRUN useradd -ms /bin/bash quarto\nUSER quarto\nRUN mkdir /home/quarto/to_serve\nWORKDIR /home/quarto/to_serve\n\n\n######\n# Start quarto serve\n######\n\nCMD quarto serve --no-browse --host 0.0.0.0 --port 4848"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#quarto-preview",
    "href": "quarto-workflows/jupyter.html#quarto-preview",
    "title": "From Jupyter",
    "section": "Quarto preview",
    "text": "Quarto preview\nLet’s start off by previewing our quarto site locally. In Terminal, type quarto preview, which will provide a URL with a preview of our site!\nquarto preview\n# Preparing to preview\n# Watching files for changes\n# Browse at https://openscapes.2i2c.cloud/user/jules32/proxy/4593/\nCopy this URL into another browser window; and arrange them so you can see them both. I make a bit more space in Jupyter by collapsing the left file menu by clicking on the file icon at the top of the left sidebar.\n\n\n\n\n\n\nMake a small change and preview it\nNow we’ll be able to see live changes in the preview as we edit in our .md files. Let’s try it: Change the date in index.md by opening it from the file directory. Change to today’s date, and save. Your preview window will refresh automatically! If it does not, you can also refresh the page manually. The refreshed previewed site will now display your changes!"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#create-a-new-.ipynb-page",
    "href": "quarto-workflows/jupyter.html#create-a-new-.ipynb-page",
    "title": "From Jupyter",
    "section": "Create a new .ipynb page",
    "text": "Create a new .ipynb page\nLet’s add a new page to our site. Instead of an .md file like the others, let’s add a .ipynb file.\nFile > New > Notebook. Accept the default kernel by clicking Select.\n\nFirst chunk: raw yaml\nBy default, this Notebook will give us a first chunk that is code. Let’s change it to raw so that we can write our yaml at the top.\n\n\n\n\n\nIn our Raw code chunk, let’s write the title of this document. We need three dashes --- on separate lines preceding and following the title:, which you can name as you’d like.\n---\ntitle: Python Example\n---\n\n\nSecond chunk: Markdown\nLet’s add a new chunk that is Markdown so we can write some description of what this page will be.\nClick the + symbol at the top of the document, and this will add a new chunk, which by default again is a Code chunk. Change it to a Markdown Chunk following the steps we did above when switching to Raw.\nHere, write a little bit of text in Markdown. Since your title is effectively a level-1 header, avoid using level-1 headers in the rest of your document. Here is some example text I wrote:\n## Introduction\n\nThis example has some Python code that will be a part of our Quarto site.\n\n\nThird chunk: Code\nNow let’s create a new chunk with the default Code setting.\nPaste the following code (or write some of your own to test):\n#| label: fig-polar\n#| fig-cap: \"A line plot on a polar axis\"\nimport numpy as np\nimport matplotlib.pyplot as plt\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\nNow, go ahead and execute this code chunk like you normally would, by clicking the cursor in a code block and clicking the sideways “play” triangle to run the selected cells (and advance to the next cell). This code produces a plot.\nNote that the code runs as it normally would; the code options in the comments are just comments.\n\n\nSave your file\nSave your document - I’ll call mine python-example.ipynb in the main repository."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#update-_quarto.yml",
    "href": "quarto-workflows/jupyter.html#update-_quarto.yml",
    "title": "From Jupyter",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nNow we’ll add python-example.ipynb to our _quarto.yml file; this is where we register of all files to include in our site. Let’s add it after the section called “Basic Workflows”.\nOpen _quarto.yml by clicking on it from the file directory.\nScroll down to review the current contents in the sidebar: section. It’s there we see all the file arrangement that we see in the previewed site.\nAdd - python-example.ipynb to line 46, making sure that your indentation aligns with the other pages.\n\n\n\n\n\nYou’ll see that our new page shows up in our Preview, and the code is executed since we did that in the Jupyter Notebook itself. By default, Quarto will not execute code chunks since your computations will likely become more complex and you will want to control when they are executed (or “run”).\nSince Quarto is still previewing our website and the python-example.ipynb, the plot also displays in the notebook after the code is run and the file is saved, as shown below.\n\n\n\n\n\nSo, your normal workflow for creating and running code blocks in your Jupyter Notebook is the same one you’ll use as Quarto displays the preview."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#quarto-render",
    "href": "quarto-workflows/jupyter.html#quarto-render",
    "title": "From Jupyter",
    "section": "Quarto render",
    "text": "Quarto render\nSo far we have used Quarto preview to view our website as we develop it. Quarto render will build the html elements of the website that we can see when we preview. Rendering will format the markdown text and code nicely as a website (or however is indicated in the _quarto.yml).\nBy default, Quarto render does not execute code in a Jupyter notebook. It will never run .ipynb files unless you tell it to.\n\nRender whole notebook\nIf you would like it to specifically execute code in a Jupyter notebook, you can do so in Terminal.\nOur Terminal is still busy previewing our website, so let’s open a new Terminal.\nFile > New > Terminal. Then type:\ncd quarto-website-tutorial\nquarto render python-example.ipynb --execute"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#authoring-tips",
    "href": "quarto-workflows/jupyter.html#authoring-tips",
    "title": "From Jupyter",
    "section": "Authoring tips",
    "text": "Authoring tips\nQuarto.org has details about authoring, including specific instructions about authoring in Jupyter: quarto.org/docs/reference/cells/cells-jupyter."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#commit-and-push",
    "href": "quarto-workflows/jupyter.html#commit-and-push",
    "title": "From Jupyter",
    "section": "Commit and push!",
    "text": "Commit and push!\nCommitting and pushing will make the changes you see locally live on your website (using the GitHub Action we set up earlier)."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#troubleshooting",
    "href": "quarto-workflows/jupyter.html#troubleshooting",
    "title": "From Jupyter",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nMy changes don’t show up in preview\nMake sure you’ve saved your file! There might be a slight delay depending on your JupyterHub/Lab setup.\n\n\nQuarto render hangs / does not complete\nCheck the specific notebook, are there any `—` throughout to denote line breaks rather than yaml? They might be causing the issue; consider deleting those.\nAlso check how long the first raw cell is. Are there level-1 headers (#)? Try removing them."
  },
  {
    "objectID": "quarto-workflows/rstudio.html",
    "href": "quarto-workflows/rstudio.html",
    "title": "From RStudio",
    "section": "",
    "text": "The RStudio software (called an IDE, integrated development environment) is an excellent way to edit files and interface with GitHub. Plus, as it is made by the same folks who make Quarto, it has many integrated features for streamlining your workflow with Quarto, including how it previews your edits and provides debugging support for yaml! Quarto's RStudio tutorials has great instructions on getting started with RStudio, including computations and authoring.\nHere is what you’ll need to do to set up and use RStudio with Quarto."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#setup",
    "href": "quarto-workflows/rstudio.html#setup",
    "title": "From RStudio",
    "section": "Setup",
    "text": "Setup\n\nRStudio and GitHub\nFor a workflow with RStudio and GitHub on your local computer, you will need four things:\n\nR\nRStudio\nGit\nGitHub\n\nFollow the UCSB MEDS Installation Guide for detailed instructions on how to create accounts, download, install, and configure on Mac and Windows. This takes about 20 minutes. (For an even more detailed walk-through, see Allison Horst’s ESM 206 Google Doc).\n\n\nClone your repo\nYou’ll start by cloning your repository into RStudio.\nFile > New Project > Version Control > Git > paste your repository name.\nR for Excel Users: Clone your repository using RStudio has detailed instructions and screenshots of these steps.\n\n\nInstall Quarto\nNext, you’ll install Quarto: https://quarto.org/docs/get-started/. After downloading, follow the installation wizard on your computer. When it is complete, you won’t see an application or any new software, but it is now available to RStudio (as well as all other applications on your computer, including the command line).\n\n\nRStudio orientation\nNow let’s take a moment to get oriented. This is an RStudio project, which is indicated in the top-right. The bottom right pane shows all the files in your project; everything we’ve cloned from GitHub. We can open any RStudio project by opening its .Rproj file, or from RStudio File > Open Project ….\n\n\n\nRStudio IDE highlighting the project name and files pane\n\n\n\n\nVisual Editor\nThe RStudio Visual Editor is quite new and has features that improve your writing experience. Working in the Visual Editor feels a bit like working in a Google Doc.\nHere’s an example showing the same file in the original Source Editor with content in markdown format and in the Visual Editor with content that looks more like it will appear in a live site. You can switch freely between these modes.\n\n\n\n\n\n\nRStudio IDE highlighting the Source Editor\n\n\n\n\n\n\n\nRStudio IDE highlighting the Visual Editor\n\n\n\n\n\nAlready have some content formatted in a Google Doc? You can copy-paste it into the Visual Editor and most formatting will be retained.\nThe editing bar provides familiar point and click access to text formatting options like bulleted or numbered lists.\n\n\n\nRStudio IDE highlighting the point and click editing bar\n\n\n\nKeyboard shortcuts\nThe Visual Editor also lets you use many keyboard shortcuts that might be familiar for adding boldface (command-b), italics (command-i), or headers. On a Mac, option-command-2 will make a level 2 header. Try it with option-command-1, or option-command-0 for normal text!\n\n\nInsert an image or figure\nTo insert an image (called a figure in Quarto), click the image icon. This brings up a window in which we can select the image, set its alignment, give it a caption and alt text, hyperlink it, or edit other metadata.\n\n\n\nInsert image or figure using the Visual Editor\n\n\nOnce an image is added, clicking on that image gives us editing options. We can resize it dynamically by clicking in the image and dragging a corner or side to resize. When an image is selected, its dimensions are displayed for editing. Clicking on the gray ellipsis to the right of the dimensions opens the pop-up window to access more metadata edits.\n\n\nInsert a table\nSimilar to adding an image, to insert a table, we click the Table dropdown."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#quarto-render",
    "href": "quarto-workflows/rstudio.html#quarto-render",
    "title": "From RStudio",
    "section": "Quarto render",
    "text": "Quarto render\nIn the Build tab in the top-right pane, click “Render Website”. This will build the .html files and preview your website. It’s equivalent to “knitting” in RMarkdown.\nNote that you can also click “Preview Website”. With “Render Website” in RStudio, Quarto is able to render and preview in one step.\nIf you’d ever like to stop the preview, in the bottom-left, click on the Jobs tab and then the red Stop button.\n\nMake a small change and render it\nClick on index.md. This will open this markdown file in a fourth pane; the editor pane. Make a small change, for example change to today’s date on Line 4. Then, save your file; there is a disc icon at the top of the file.\nThen, render this file: press “Render” which is to the right of the disc icon that saves the file. This will render only this single file, as opposed to rerendering the whole website like when we clicked “Render Website” in the top right pane. Checking Render on Save (between the disc icon and the Render button) is a great strategy for doing this in one step."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#create-a-new-.rmd-page",
    "href": "quarto-workflows/rstudio.html#create-a-new-.rmd-page",
    "title": "From RStudio",
    "section": "Create a new .Rmd page",
    "text": "Create a new .Rmd page\nNew > RMarkdown document > OK\nThe starter RMarkdown document has some R code inside: it displays a summary of the cars dataset that is pre-loaded into R (summary(cars)) and plots the pressure data that is also pre-loaded (plot(pressure)).\nSave this document as r-example.rmd."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#update-_quarto.yml",
    "href": "quarto-workflows/rstudio.html#update-_quarto.yml",
    "title": "From RStudio",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nNow we’ll add r-example.rmd to our _quarto.yml file; this is where we register all files to include in our site. Let’s add it after the section called “Quarto Workflows”.\nOpen _quarto.yml by clicking on it from the file directory.\nScroll down to review the current contents in the sidebar: section under contents:. It’s there we see all the file arrangement that we see in the previewed site.\nAdd - r-example.rmd in its own line, making sure that your indentation aligns with the other pages.\nFrom the Build tab, clicking Preview Website will recreate your website!"
  },
  {
    "objectID": "quarto-workflows/rstudio.html#authoring-tips",
    "href": "quarto-workflows/rstudio.html#authoring-tips",
    "title": "From RStudio",
    "section": "Authoring tips",
    "text": "Authoring tips\nChecking “Render on Save” is really helpful when iterating quickly on a document.\nIf the document is very code-heavy, consider using freeze that will not run the code each time.\nQuarto.org has details about authoring, including specific instructions about authoring in RStudio."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#commit-and-push",
    "href": "quarto-workflows/rstudio.html#commit-and-push",
    "title": "From RStudio",
    "section": "Commit and push!",
    "text": "Commit and push!\nCommitting and pushing will make the changes you see locally live on your website (using the GitHub Action we set up earlier)."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#troubleshooting",
    "href": "quarto-workflows/rstudio.html#troubleshooting",
    "title": "From RStudio",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nIf you have trouble rendering your website after for example changing the extenstion of a file from .md to .qmd, refreshing your RStudio often helps. Do this by clicking the project name at the upper right of the RStudio window (in this case, quarto-website-tutorial), and underneath the “close project” section, click the same name of your project: quarto-website-tutorial. This will relaunch your whole project afresh."
  },
  {
    "objectID": "quarto-workflows/index.html",
    "href": "quarto-workflows/index.html",
    "title": "Quarto workflows",
    "section": "",
    "text": "How do you work in Quarto? You can use whichever tool you’re comfortable with (RStudio, Jupyter, GitHub, VS Code, etc). Developing your quarto site will have the same basic workflow, no matter which tool you use. It is very iterative, and each is explored more below.\n\nAuthoring: write text, code, images, etc in a file. Supported files include .md, .Rmd, .qmd, .ipynb…\nUpdate _quarto.yml as needed (for example, if you’ve created a new file you’d like included in your site)\nRender individual files and/or the whole website\nRepeat, repeat, repeat\nCommit and push your website to GitHub, your updates will publish automatically!\nRepeat all of the above to make the website as you’d like!\n\nNote: if editing from your internet browser we won’t render in Step 3. That step will not be separate, but combined with Step 5, which will only require a commit, not a push."
  },
  {
    "objectID": "quarto-workflows/index.html#authoring",
    "href": "quarto-workflows/index.html#authoring",
    "title": "Quarto workflows",
    "section": "Authoring",
    "text": "Authoring\nAs an author, you have a lot of options of how your text will be formatted, arranged, and interlinked. You will be writing in Markdown, which is a lightweight text formatting language. The Quarto documentation about authoring introduces markdown-basics that will get you started. Also see Mine Çetinkaya-Rundel’s A Quarto tip a day.\nEach page of our site has a similar first few lines - this YAML, like we saw in our _quarto.yml and it is indicated by two sets of 3 dashes --- :\n---\ntitle: My title\n---\nYou’re able to add more features to individual pages by including it in the YAML, which for the most part here only includes a title. See Quarto excecution options for more information of what you can include in the YAML."
  },
  {
    "objectID": "quarto-workflows/index.html#update-_quarto.yml",
    "href": "quarto-workflows/index.html#update-_quarto.yml",
    "title": "Quarto workflows",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nLet’s have a closer look at the _quarto.yml file.\nThis type of file (.yml or .yaml) is written in YAML (“Yet Another Markup Language”). You’ll be able to shift the arrangement of webpages by reordering/adding/deleting them in the _quarto.yml file following the patterns you see in this example.\n\n\n\n_quarto.yml and website side-by-side\n\n\nNotice that there are multiple ways in the _quarto.yml for you to include a file in your website. For example, in the above image, the “First Observations” we see in the left sidebar of the published website (right image) is represented in _quarto.yml (left image) over two lines, with line 36 indicating the file reference and line 37 indicating the text to show up in the left sidebar. However, “From RStudio” is only represented in one line of _quarto.yml, on line 43. This represents two strategies for including a file in your website. By default, the title of a specified file will show up in the website’s sidebar, which is what is happening with the “From RStudio” example. If you would like more control over what is written in the sidebar vs the title of your files, then the approach we took with “First Observations” is what you’ll want to do: you’ll see that only “First Observations” shows up in the sidebar as we specified in _quarto.yml, but the page’s title says “First Observations & Setup” (which in our preference was too long for the sidebar).\n\n\n\n\n\n\nNote\n\n\n\nAs you modify _quarto.yml, the most important thing to know is that spacing matters. Pay attention to whether text is indented by one, two, four, or other spaces, and make sure you follow it; if your site is not looking as expected it is likely a silent error in your YAML. Some text editors like RStudio provide debugging support for YAML and are highly recommended to save you time and heartache."
  },
  {
    "objectID": "quarto-workflows/index.html#install-quarto",
    "href": "quarto-workflows/index.html#install-quarto",
    "title": "Quarto workflows",
    "section": "Install Quarto",
    "text": "Install Quarto\nhttps://quarto.org/docs/get-started/ describes how to install Quarto, which will depend on your operating system. We’ll walk through installation for each tool in the next chapters."
  },
  {
    "objectID": "quarto-workflows/browser.html",
    "href": "quarto-workflows/browser.html",
    "title": "From the Browser",
    "section": "",
    "text": "A workflow from the browser if good for getting started (since you do not need to install additional software) and for making small contributions, but is definitely limited. Once you feel comfortable here, you can move to a different setup.\nHere’s an example of editing content on an existing page."
  },
  {
    "objectID": "quarto-workflows/browser.html#edit-content-on-an-existing-page",
    "href": "quarto-workflows/browser.html#edit-content-on-an-existing-page",
    "title": "From the Browser",
    "section": "Edit content on an existing page",
    "text": "Edit content on an existing page\nLet’s change the date on the home page of this website.\nIn your repository, navigate to index.md. Then, click the pencil icon in the top right to edit directly.\n\n\n\n\n\nWe are now in the “Edit file” tab of the editor, where we can make modifications. Let’s change the date to today’s date. Click the “Preview” tab to see your changes. You can even check the “Show diff” box on the right side to see the changes you’ve made.\n\n\n\n\n\nWhile you’re here, see if there are additional changes to the text you’d like to make. Maybe changing the title or author at the top, or for the main text on the home page of the website.\nOur index.md file is written in Markdown, which enables you to make simple text formatting. As you go back and forth from “Edit file” to “Preview”, notice the patterns of how the Markdown text looks when it is as source (“Edit file”) and when it is formatted (“Preview”). For example, in Markdown, you can make text as a header with # symbols, bold or italic with * symbols, and hyperlinks with [](). Notice that spacing is important: for example, there are carriage returns (when you hit the “return” key) before any bullet points. You can learn the short list of Markdown rules here: https://quarto.org/docs/authoring/markdown-basics."
  },
  {
    "objectID": "quarto-workflows/browser.html#commit-and-publish",
    "href": "quarto-workflows/browser.html#commit-and-publish",
    "title": "From the Browser",
    "section": "Commit and publish",
    "text": "Commit and publish\nCommit your changes by scrolling to the bottom of the page and writing a commit message - a note to yourself and others about what changes you made. Write your commit message and then click the green “Commit changes” button.\n\n\n\n\n\nNow, click back to the main page of your GitHub repository. You should see the orange dot confirming your website is published. You’ll have to wait for the GitHub Action to tell quarto to build your site for you to see the update, but it will be there!"
  },
  {
    "objectID": "quarto-workflows/browser.html#limitations",
    "href": "quarto-workflows/browser.html#limitations",
    "title": "From the Browser",
    "section": "Limitations",
    "text": "Limitations\nWhile awesome that we can edit using GitHub directly from the browser, there are obvious limitations. One is that to see your edits show up in your book, you have to publish using the GitHub Action. This is slow. Another limitation is that we can only work on one file at a time and commit them each separately, which also is slow. Using additional software can make things much better, as we explore in subsequent chapters."
  },
  {
    "objectID": "learning-more.html",
    "href": "learning-more.html",
    "title": "Learning more",
    "section": "",
    "text": "An excellent overview: Reproducible authoring with Quarto - Mine Çetinkaya-Rundel, Feb 2022 - slides, youtube\nA Quarto tip a day in June 2022, from Mine Çetinkaya-Rundel.\n\n\n\nOpenscapes Champions Lessons Series\nOpenscapes Approach Guide\n\nNASA Earthdata Cloud Cookbook\n\nSee many more examples at the quarto gallery!\n\n\n\nAre you making onboarding documentation? Check out The Fay Lab Manual (now in Quarto!) for inspiration on structure - you could also start there and make it your own."
  },
  {
    "objectID": "planning.html",
    "href": "planning.html",
    "title": "Planning Steps",
    "section": "",
    "text": "Planning steps include pre-deployment coordination and communication best practices that help ensure that any new deployments are responsive to PAM data gaps and needs in the region (to the extent practicable), and that individuals or entities responsible for deployments and data are connected to the existing network of experts and can benefit from lessons learned and other existing bodies of knowledge."
  },
  {
    "objectID": "planning.html#i.-engage-with-the-rwsc-marine-mammal-subcommittee",
    "href": "planning.html#i.-engage-with-the-rwsc-marine-mammal-subcommittee",
    "title": "Planning Steps",
    "section": "I. Engage with the RWSC Marine Mammal Subcommittee",
    "text": "I. Engage with the RWSC Marine Mammal Subcommittee\nGroups or individuals planning to deploy PAM devices on the Atlantic OCS for the purposes of detecting cetaceans or characterizing ocean noise are encouraged to attend RWSC Marine Mammal Subcommittee meetings to introduce their project, discuss their deployment plan with experts, and receive input on optimal location and other considerations (visit https://rwsc.org/events to view the Subcommittee meeting schedule). In collaboration with the NOAA Passive Acoustics Research Group, the Subcommittee is maintaining an understanding of PAM devices deployed on the Atlantic OCS and periodically updating maps that show current deployments on the Northeast Ocean Data Portal and Mid-Atlantic Ocean Data Portal (see figure below).\nThe Portal maps are developed from location and deployment information shared with NOAA. The following best practices ensure that information about new and completed deployments is shared with NOAA so that the Portal maps maintain their accuracy and relevance.\nThe Portals also contain data products that may assist funders and researchers in selecting locations for PAM deployment. For example, the Portals contain data products representing monthly and annual vessel traffic for several classes of vessels; commercial fishing activity; offshore wind planning and leasing areas; bathymetry and seafloor composition information; and monthly density model outputs for 29 cetacean species/guilds. The Subcommittee encourages users to examine these data to inform PAM deployment site selection."
  },
  {
    "objectID": "planning.html#ii.-codeployment-of-other-sensors",
    "href": "planning.html#ii.-codeployment-of-other-sensors",
    "title": "Planning Steps",
    "section": "II. Codeployment of other sensors",
    "text": "II. Codeployment of other sensors\nIntroducing new PAM instruments and moorings into the environment presents an opportunity to co-locate other sensors and equipment. For example, several active and planned PAM deployments include support for VEMCO receivers or other acoustic telemetry receiver devices. This type of co-deployment builds the receiver network for studies of other taxa such as sea turtles and highly migratory fish species, and is strongly encouraged.\nWhile the location of PAM instruments and moored PAM arrays may not represent ideal receiver locations needed to address research questions answered with acoustic telemetry for other taxa, RWSC and its partners encourage the deployment of multiple sensors per mooring, when practicable, while research questions and best practices for acoustic telemetry are under development.\nIn August 2022, the RWSC Sea Turtle Subcommittee recommended that acoustic telemetry receivers be included on each new PAM deployment as the RWSC Marine Mammal Subcommittee considers the design and implementation of a regional PAM network."
  },
  {
    "objectID": "planning.html#iii.-best-practices-to-minimize-bottom-disturbance-from-underwater-mooring-systems",
    "href": "planning.html#iii.-best-practices-to-minimize-bottom-disturbance-from-underwater-mooring-systems",
    "title": "Planning Steps",
    "section": "III. Best Practices to minimize bottom disturbance from underwater mooring systems",
    "text": "III. Best Practices to minimize bottom disturbance from underwater mooring systems\nParticipants in the June 2021 BOEM/NOAA Workshop “Improving Monitoring, Data Consistency, Archiving, and Access for Improved Regional Integration of Renewable Energy Science” recommended that best management practices (BMPs) be developed for any moored or bottom-mounted equipment used for mitigation, monitoring, and regional science associated with offshore wind development. These recommended BMPs are intended to address identified issues but are voluntary and should be considered supplemental to any other requirements that may be included under federal or state permits and authorizations. The purpose of the following BMPs is to provide reasonable conditions to avoid ocean use conflicts and minimize any potential environmental impacts associated with scientific devices on or attached to the seafloor.\n\nReview information in ocean data portals and confer with offshore wind developers to ensure device deployment areas do not conflict with existing or planned cable locations, rights of way, or foundation locations.\nProperly label all buoys and devices with the responsible operator name and contact information.\nAvoid known locations of possible unexploded ordnance (UXO).\n\nAvoid historical or archeological sites.\n\nAvoid known live bottom (corals, seagrasses, etc.) and sensitive hard-bottom features.\n\nReduce entanglement or entrapment risk to marine protected species.\n\nUtilize ocean data portals and coordinate with offshore wind developers. To the greatest reasonable extent practicable, deployment locations should be deconflicted prior to deploying any research or monitoring equipment on the seafloor. Coordination should occur with offshore leaseholders within lease boundaries and cable rights of way to ensure current or planned development activities do not conflict with the deployment or operation of the device.\nProperly label all equipment with the responsible operator name and contact information. Including identification information on equipment will assist with identifying the responsible parties for any equipment that is lost, damaged, or otherwise recovered that is separated from its moorings.\nAvoid UXO. Avoidance should be the primary strategy to ensure potential locations of UXO are not interacted with during the deployment, maintenance, and recovery of scientific devices. Information for known ordnance areas are available at https://marinecadastre.gov/data/ and should be checked when identifying potential device locations and prior to equipment re-deployment. New potential UXO may also be identified by geophysical and magnetometer surveys associated with offshore wind data collection.\nAvoid known Historical and archeaological sites. If the mooring system, anchoring, or equipment (any portion of bottom disturbance) is to be placed in an area known to be clear or otherwise was previously surveyed and cleared, then no additional surveys are required. If the area was previously surveyed and the equipment is associated with proposed actions under an OCS lease, the lessee should coordinate with BOEM on any necessary requirements under a lease or approval conditions of plans.\nAvoid live-bottom features. Mooring systems or equipment sleds should occur at least 150 m from any known locations of threatened or endangered coral species. All sensitive live bottom habitats (eelgrass, cold-water corals, etc.) should be avoided as practicable. Hard-bottom features including pavement, scarp walls, and deep/cold-water coral reefs and shallow/mesophotic reefs as defined in the CMECS Geologic Substrate Classifications) should also be avoided.\nReduce entanglement and entrapment risk. Mooring or retrieval systems should have a discountable risk of entangling or entrapping any marine protected species. Operators should ensure that any buoys attached to the seafloor use the best available mooring systems. Buoys, lines (chains, cables, or coated rope systems), swivels, shackles, and anchor designs should prevent any potential entanglement of listed species while ensuring the purpose, safety, and integrity of the structure or device. All mooring lines and ancillary attachment lines should use one or more of the following measures to reduce entanglement risk: shortest practicable line length, rubber sleeves, weak-links, chains, cables, or similar equipment types that prevent lines from looping, wrapping, or entrapping protected species. Any equipment should be attached by a line within a rubber sleeve for rigidity. The length of the line should be as short as necessary to meet its intended purpose."
  },
  {
    "objectID": "planning.html#iv.-best-practices-to-minimize-self-noise-from-underwater-mooring-systems",
    "href": "planning.html#iv.-best-practices-to-minimize-self-noise-from-underwater-mooring-systems",
    "title": "Planning Steps",
    "section": "IV. Best Practices to minimize self-noise from underwater mooring systems",
    "text": "IV. Best Practices to minimize self-noise from underwater mooring systems\nPrecautions should be taken to avoid interference of self-noise caused by current flow around the hydrophone and movement of the device and its components. This is especially important in areas with currents greater than 0.1 m/s; to estimate bottom currents for a potential site use the HYCOM model provided by NOAA (https://coastwatch.pfeg.noaa.gov/erddap/griddap/). Flow shields and/or wraps that protect hydrophones and other device components can also be used to decrease self-noise by disrupting the turbulent boundary layers (ADEON Hardware Specification ). An example of quiet mooring design is described in Baumgartner 2019:\n\nWe utilized a mature mooring design that allowed both quiet operation as well as delivery of digital data from the sea floor to shore (Figure 2.1). The DMON was housed in open cell foam and a urethane fairing and affixed to a bottom-mounted aluminum frame called the multi-function node (MFN), which in turn was attached to the surface buoy by stretch hoses. These hoses can stretch to nearly twice their relaxed length (Paul & Bocconcelli, 1994), thereby absorbing the motion of the buoy in rough wave conditions and keeping the MFN acoustically quiet. The hoses also contain helically wound conductors that allow power and data to be delivered between the buoy and the DMON. The surface buoy contains a platform computer, Iridium and global positioning satellite (GPS) antennas, and a 450-Ahr battery pack to power all system components. The platform computer receives and stores DMON/LFDCS data sent in real-time via the stretch hoses, and once every 2 hours, transmits these stored data to shore via an Iridium satellite modem (Figure 2.2). The buoy was designed to operate at sea for at least one year."
  },
  {
    "objectID": "planning.html#v.-navy-awareness-of-pam-deployments-on-the-atlantic-ocs",
    "href": "planning.html#v.-navy-awareness-of-pam-deployments-on-the-atlantic-ocs",
    "title": "Planning Steps",
    "section": "V. Navy Awareness of PAM deployments on the Atlantic OCS",
    "text": "V. Navy Awareness of PAM deployments on the Atlantic OCS\nThe purpose of the following steps is to ensure that the US Navy is aware of and can provide feedback on the precise location of bottom-mounted archival passive acoustic monitoring equipment on the Atlantic OCS. The Navy is requesting that all individuals consider the following steps prior to deployment. Developers may be subject to additional requirements under the BOEM issued permits.\n\nEnsure Navy awareness - 45 days prior to deployment Submit Passive Acoustic Monitoring (PAM) and/or Distributed Acoustic Sensing (DAS) plan to Navy (latitude/longitude, type, make and model of sensor, water depth, sample rate, time frame, deployment duration etc.). Email Beth Levy: beth.m.levy2.ctr@us.navy.mil\nNavy evaluation and response This step applies to PAM data in all locations, not just BOEM lease areas. Provide at least 30 days for Navy to evaluate the plan from an operational and acoustic security perspective.\n\nNavy Concurs - The Fleet is able to operate with the proposed plan as is. No data screening is needed.\nNavy Concurs with requested conditions\n\nRequest Alternative Sensor Location: Navy proposes alternative locations that will still allow for original monitoring objectives, while maintaining National Security, Navy training and readiness.\nRequest Data Screening: Navy would request the ability to screen data from selected sensors and redact potentially sensitive data. The screened data set will be returned to the owner/collector for their unrestricted use and dissemination.\n\n\nOperator confirms sensor deployment locations\n\nAfter actual sensor deployment, provide precise metadata to Navy within 7 days.\n\nOperator data retrieval\n\nIf sensor is not identified for screening, operator can proceed with QA/QC and data analysis.\nIf sensor is identified for requested screening, load data onto hard drives, record metadata about location, water depth, etc.\n\nBEFORE an analyst does any QA/QC, follow existing Navy data handling and secure storage procedures (a detailed document will be provided during step 2 above).\nData will be sent to Navy for screening.\nNavy will review and return a redacted data set within 90 days. o Operator can proceed with analysis on the redacted dataset.\n\n\nInstrument recovery/redeployment Operator will notify Navy if instruments are recovered, and/or redeployed in the same location, or if settings or location have changed, will restart with step 1 above."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Long-term and Archival Passive Acoustic Monitoring (PAM) Data",
    "section": "",
    "text": "This document was compiled by RWSC Staff at the request of the Marine Mammal Subcommittee with the assistance and input of a PAM Data Management Work Group. Work Group members and reviewers of this document included: Melinda Rekdahl (Wildlife Conservation Society); Anita Murray (Wildlife Conservation Society; now Maine Department of Marine Resources); Erin Meyer-Gutbrod (University of South Carolina); Erica Staaterman (BOEM); Genevieve Davis (NOAA NEFSC Passive Acoustics Research Group); Jordan Carduner (Equinor), Laura Morse (Orsted; now Mainstream Renewables); Scott Carr (JASCO); Aaron Rice (Cornell University); Joel Bell (US Navy); Carrie Wall Bell (NOAA National Centers for Environmental Information (NCEI)).\n\nThis document is also responsive to the needs and priorities expressed at recent workshops and expert working group proceedings, including:\n\n“Standards for PAM reporting” was identified as a Potential Research Idea and Priority during the New York Bight Passive Acoustic Monitoring Workshop in March 2021\nThe need and foundation for the following best practices document was discussed at the June 2021 BOEM/NOAA workshop Improving Monitoring, Data Consistency, Archiving, and Access for Improved Regional Integration of Renewable Energy Science: Passive Acoustic Monitoring and Marine Mammals\nThe specific components and building blocks for the following best practices were discussed and many Subcommittee members participated in the March 2022 BOEM/NOAA workshop Improving Monitoring, Data Consistency, Archiving, and Access for Improved Regional Integration of Renewable Energy Science: Passive Acoustic Monitoring Data Standards and Management\n\nThe purpose of this document is to address the data collection, management, and storage phases of a long-term/archival PAM project to ensure that while numerous individual entities may be deployment, collecting, and analyzing PAM data, the infrastructure and information exists to facilitate future meta-analyses and syntheses of PAM data across the U.S. Atlantic Outer Continental Shelf (OCS). For specific guidance and information regarding PAM systems and their deployment and the PAM capabilities and techniques needed to promote efficient, consistent, and meaningful data collection efforts on local and regional scales, please see the minimum recommendations for PAM usage in offshore wind energy research developed by NOAA and BOEM (Van Parijs et al. 2021). This PAM data management and storage best practices document incorporates by reference many of the specifications and recommendations of Van Parijs et al. 20215. In addition, the multi-year and multi-sector Atlantic Deepwater Ecosystem Observatory Network for the US Mid- and South Atlantic Outer Continental Shelf (ADEON) project developed several standardized measurement and processing methods to ensure that the underwater acoustic measurements made over the course of its project can be compared with other monitoring programs’ data. ADEON data guides and specifications are incorporated by reference throughout this document as well.\nThis document does not directly address or recommend best practices for deploying PAM for real-time detection of marine mammals for mitigation purposes (Table 1). U.S. federal agencies may provide requirements or guidance for the deployment, interpretation, reporting, and management of real-time mitigation PAM data in association with offshore wind (or other activities/uses) permitting. The data generated from real-time systems used for mitigation (I.e., species detections) may be integrated into PAM data products as part of the final step of the workflow described below, with additional considerations for differences in study design, collection methods, and other data analysis steps.\n\nTable 1. Various purposes for deploying PAM and relevance to this document\n\n\n\n\n\n\n\n\nPurpose\nReal-time PAM\nArchival PAM\nConsiderations for deployment and best practices for data management included in this document?\n\n\n\n\nMitigation during pile driving or other noise-generating activities\nx\n\nNo\n\n\nVessel strike avoidance\nx\n\nNo\n\n\nAmbient noise monitoring\nx\nx\nYes\n\n\nLong-term wildlife monitoring\n\nx\nYes\n\n\n\nThe document is separated into three sections that correspond to a generic workflow for planning, deploying, and analyzing/interpreting long-term archival PAM data, primarily for the purposes of detecting cetaceans. Each section contains several detailed steps that were identified by the RWSC Marine Mammal Subcommittee."
  },
  {
    "objectID": "deployment-data.html",
    "href": "deployment-data.html",
    "title": "Deployment & Data Collection",
    "section": "",
    "text": "The following sections outline steps in the deployment of PAM hardware and the collection and collating of PAM data. Best practices associated with each step are described, and/or existing resources on the topic are referenced.\nThis document recognizes that deployment and data collection steps are likely specifically established by entities deploying instruments and collecting data; and in some case these procedures could be proprietary. The following steps outline minimum considerations for ensuring that data being collected by various entities around the region can eventually be collated and analyzed in the future to examine regional-scale questions or issues of interest."
  },
  {
    "objectID": "deployment-data.html#vi.-definitions-for-raw-processed-cleaned-and-analyzed-data",
    "href": "deployment-data.html#vi.-definitions-for-raw-processed-cleaned-and-analyzed-data",
    "title": "Deployment & Data Collection",
    "section": "VI. Definitions for raw, processed, cleaned, and analyzed data",
    "text": "VI. Definitions for raw, processed, cleaned, and analyzed data\nIt is expected that PAM data are collected to obtain (either or both) species detection information (e.g., cetacean calls) and ambient or other noise information (e.g., ship detections, construction noise, etc.).\nThe following data levels (corresponding to the levels described in ADEON’s Data Processing Specification document) apply to both types of information and will be used to define what type of data are being referred to in each of the subsequent sections. These levels correspond to a workflow beginning with raw data downloaded directly from the instrument, to processed, cleaned, and/or analyzed data that have been interpreted to develop data products. There are different specifications and data management steps associated with different parts of the workflow. The grouped levels below are a reflection of when similar specifications and data management steps can be applied.\n\n\n\n\n\n\n\nLevel\nMeaning\n\n\n\n\n0\nRaw, uncalibrated data; compressed, unpacked data\nExamples: binary files (e.g., BIN, DAT) and SUD compressed files; before the calibration information is applied\n\n\n1\nCalibrated time series data\nExamples: .wav files (e.g., WAVE, AIFF, FLAC); data processed using software, after calibration is applied; sound pressure on a stationary or moving platform\n\n\n2-3\nProcessed data from the calibrated data (quantitative and qualitative). Quantitative processing (temporal or spatial)\nExamples: decidecade levels; SEL; depth-integrated data; beamformed data; whale or ship detections/observations; products related to classification of signals; products related to signal localization\n\n\n4-5\nSynthesized products related to soundscape models/maps and predictive habitat modeling. Requires additional information (e.g., AIS, source model)\nExamples: interpolated products; marine mammal density estimation\n\n\n\nThe following flow chart was also adapted from ADEON’s Data Processing Specification document to depict the basic sequence of data analysis and reporting suggested for each data level. The rest of this document provides detailed steps and templates for each part of the workflow."
  },
  {
    "objectID": "deployment-data.html#vii.-pam-hardware-calibration-best-practices-and-minimum-specifications",
    "href": "deployment-data.html#vii.-pam-hardware-calibration-best-practices-and-minimum-specifications",
    "title": "Deployment & Data Collection",
    "section": "VII. PAM hardware calibration best practices and minimum specifications",
    "text": "VII. PAM hardware calibration best practices and minimum specifications\n\n(Level 0 data to Level 1 data)\nThe following steps pertain to pre-deployment best practices.\n\n\nCalibration process\nFor specific examples and details about PAM hardware calibration, refer to ADEON Calibration and Deployment Good Practice Guide, which, while limited to the specific instruments used in the ADEON project, is useful regardless of the system being used.\nThe following text was taken from NOAA and BOEM Minimum Recommendations for Use of Passive Acoustic Listening Systems in Offshore Wind Energy Development Monitoring and Mitigation Programs (Van Parijs et al., 2021) and refers to specific recommended calibration steps.\n\nFor all PAM technologies, the hydrophones and related hardware need to be calibrated (every 3 to 5 years) and their performance systematically measured and optimized within frequency bandwidths of interest for the particular activity, species, and environment.\nAll hardware should be tested and optimized for low self-noise, including the mooring system. In addition to calibration, the system should be fully tested to ensure adequate sensitivity in the area where it will be deployed and with the type of signals it would receive. Additional environmental data will need to be collected to allow for adequate system evaluation. If this cannot be done at the project site, the system should be fully tested in a comparable location (i.e., an area exhibiting similar depth, temperature, substrate, current, acoustic propagation, and ambient noise, with relevant sound sources).\nIdeally, the PAM technology used should have been used for the same purpose in other field efforts and have clear and detailed information available about its previous performance and reliability for PAM purposes. If this is not the case, this information needs to be gathered and provided in publicly available documentation as part of the PAM project.\n\n\n\nCalibration data and metadata\nFrom NOAA and BOEM Minimum Recommendations for Use of Passive Acoustic Listening Systems in Offshore Wind Energy Development Monitoring and Mitigation Programs (Van Parijs et al., 2021):\n\nCalibration data, and relevant settings and sensitivities should be noted for all hardware used in recording/monitoring to ensure consistency among measurements for particular hardware and software [more detail can be found in Biber et al. (2018) ]. Array synchronization information (where relevant) should also be documented. This information should be permanently associated with the recordings as metadata.\nAt a minimum, the following specifications should be measured and reported on:\n\nBandwidth and frequency response (i.e., 10 to 200 kHz)\nSystem sensitivity (i.e., −207 dB re 1 V/μPa @ 1 kHz) and dynamic range (dB)\nSystem self-noise (i.e., the equivalent bandwidth noise pressure level)\nGain (dB)\nDirectional response (i.e., omnidirectional or angular dependent)\nSample rate (kHz)\nSample resolution (i.e., 12 Bits)\nRecording schedule (i.e., recording duration/interval)"
  },
  {
    "objectID": "deployment-data.html#viii.-best-practices-for-pam-data-qaqc",
    "href": "deployment-data.html#viii.-best-practices-for-pam-data-qaqc",
    "title": "Deployment & Data Collection",
    "section": "VIII. Best practices for PAM data QA/QC",
    "text": "VIII. Best practices for PAM data QA/QC\n\n(Level 0 data to Level 1 data)\nOnce hardware is deployed and data are collected, Quality Assurance/Quality Control steps should be taken to ensure integrity of the data. This step is further split into two separate procedures to include actions that should be taken to properly download and check the data from a PAM device as well as the process to QA/QC the data after being downloaded.\n\n\nBefore downloading data from the recorder\n\n(Level 0 data)\nFor each PAM deployment there should be an associated deployment information file that contains the recording metadata and calibration information as described above in Section VII. Ensure that these data and the acoustic data files match up and are collated correctly prior to deleting any information off of the actual device. For additional detail on post-retrieval field calibration and data handling best practices, refer to the ADEON Calibration and Deployment Good Practice Guide .\n\n\n\nAfter downloading data from the recorder\n\n(Converting Level 0 data to Level 1 data)\nThe following procedure was provided by NOAA-NEFSC Passive Acoustic Research Group via Genevieve Davis:\nAcoustic Recorders\n\nCreate standardized project naming system to separate data from each deployment.\n\nPossible naming structure could be as follows:\n[RECORDER_ID]_[RECORDING_LOCATION]_[YYYYMMDD of recording start date]_[SITE_NAME]\nIt may be helpful to create folders that separate audio files from other files (i.e., log, xml files or raw, uncompressed files)\n\nSpot-check sound files:\n\nLoad audio files into sound analysis software (i.e., Raven Pro) and check waveform/spectrograms throughout the deployment: at a minimum, beginning, middle, end\nTake a listen to make sure all looks/sounds ok\n\nVerify (and/or record) metadata information on sound files in sound analysis software\n\nCheck that date/times line up in sound files with what is recorded in metadata sheets for:\n\nDeployment datetime (gmt)\nRecovery datetime (gmt)\nRecording start datetime (gmt)\nRecording end datetime (gmt)\nUsable start datetime (gmt) (when recorder is on and in the water- might be at the beginning of no vessel noise after deployment)\nUsable end datetime (gmt) (when recorder is no longer on, in the water- might be the start of recovery vessel noise)\nDid the recorder stop recording early?\nDid the data get corrupted at any point during the deployment?\n\n\nClip beginning and end of deployment to remove invalid data\n\nRecordings when recorder is out of water, or corrupted data\n\nCheck data for gaps:\n\nRun a gap detector analysis to make note of any gaps in data\n\nScripts can be written in Matlab, etc., to do this\n\n\nCheck hydrophone recordings/quality\n\nWas hydrophone working properly the whole time?\nGood practice to do for all deployments, all recorders. It can help identify instruments that are failing, or data that is corrupted and cannot be used for any or certain analysis such as soundscape metrics, or identify certain frequencies that were compromised by recorder.\nDone by calculating TOL (third octave level) metrics:\n\nExample: using scripts (Matlab, etc.) to subsample recordings to look at 1-2 minutes at start of every sound file\n\nIf there are other issues discovered that should be looked at more closely too\n\n\nAdditional Instrument Types (Examples)\n\nActive receivers (ex. VEMCO receivers/acoustic releases)\n\nCheck to see if there are detections using the chart view in Vue (this is specific for VEMCO receivers) software. Zero detections do not always indicate a problem, but are a good start.\n\nTemperature loggers (internal within a recorder, or external instruments)\n\nPlot data output to make sure nothing looks out of the ordinary"
  }
]